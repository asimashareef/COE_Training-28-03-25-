{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84a7498-0ee3-419b-915b-d389cf952e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 2.4/12.8 MB 12.2 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.7/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 11.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 11.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74fd309e-126a-47ff-a77f-d7703f6fc9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cvr\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.8 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.2/11.8 MB 10.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.3/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.2.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.3 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.6/6.3 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.4 MB 11.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.5/5.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.4 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.4 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b13deed-6fad-4ddf-97da-88d86b3fc4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\CVR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\CVR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdd1d081-11ca-4292-92db-c40be29017b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a955de55-a114-4fad-8a20-386012a0bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy's NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbe12559-b650-4d46-9dca-c634826a10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "text = \"John works at Google in California. He loves programming and playing football.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21f16ae4-58b4-4166-bc5e-cd1e5a64b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation: ['John works at Google in California.', 'He loves programming and playing football.']\n"
     ]
    }
   ],
   "source": [
    "# 1. Segmentation (sentence tokenization)\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Segmentation:\", sentences)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d8197fa-3831-4324-bb34-5228a3275404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization: [['John', 'works', 'at', 'Google', 'in', 'California', '.'], ['He', 'loves', 'programming', 'and', 'playing', 'football', '.']]\n"
     ]
    }
   ],
   "source": [
    "# 2. Tokenization (word tokenization)\n",
    "tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "print(\"Tokenization:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4051c4a9-9bbc-4511-950d-5a056e3580ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming: [['john', 'work', 'at', 'googl', 'in', 'california', '.'], ['he', 'love', 'program', 'and', 'play', 'footbal', '.']]\n"
     ]
    }
   ],
   "source": [
    "# 3. Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [[stemmer.stem(token) for token in sentence] for sentence in tokens]\n",
    "print(\"Stemming:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1c6204d-9178-42e7-8ad1-2b62fee1dbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization: [['John', 'work', 'at', 'Google', 'in', 'California', '.'], ['He', 'love', 'programming', 'and', 'playing', 'football', '.']]\n"
     ]
    }
   ],
   "source": [
    "# 4. Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [[lemmatizer.lemmatize(token) for token in sentence] for sentence in tokens]\n",
    "print(\"Lemmatization:\", lemmatized_tokens)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a34d5604-a5c1-4510-91b2-fc6abf6ed8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging: [('John', 'PROPN'), ('works', 'VERB'), ('at', 'ADP'), ('Google', 'PROPN'), ('in', 'ADP'), ('California', 'PROPN'), ('.', 'PUNCT'), ('He', 'PRON'), ('loves', 'VERB'), ('programming', 'VERB'), ('and', 'CCONJ'), ('playing', 'VERB'), ('football', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "# 5. POS Tagging\n",
    "doc = nlp(text)\n",
    "pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "print(\"POS Tagging:\", pos_tags)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad5e17e2-478e-40cb-baa8-51886656f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [('John', 'PERSON'), ('Google', 'ORG'), ('California', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "# 6. Named Entity Recognition (NER)\n",
    "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "print(\"Named Entities:\", entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1a11955-e047-4044-8db1-022433872162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John       -> nsubj      -> works\n",
      "works      -> ROOT       -> works\n",
      "at         -> prep       -> works\n",
      "Google     -> pobj       -> at\n",
      "in         -> prep       -> works\n",
      "California -> pobj       -> in\n",
      ".          -> punct      -> works\n",
      "He         -> nsubj      -> loves\n",
      "loves      -> ROOT       -> loves\n",
      "programming -> xcomp      -> loves\n",
      "and        -> cc         -> programming\n",
      "playing    -> conj       -> programming\n",
      "football   -> dobj       -> playing\n",
      ".          -> punct      -> loves\n"
     ]
    }
   ],
   "source": [
    "# 7. Parsing (Dependency Parsing)\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        print(f'{token.text:10} -> {token.dep_:10} -> {token.head.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb09849-04ea-4b1b-8ae8-4d538cd4cf67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
